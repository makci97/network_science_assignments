{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical Assignment — Influence propagation and agent based models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first part of the assignment is devoted to models of influence propagation: the linear threshold model and independent cascade model. There are many applications of these types of models, for example:\n",
    "* Rise of a political movement in an unstable society\n",
    "* “Word-of-mouth” effects: when we have access to plentiful information, such as when we evaluate new technologies, risky financial assets, or job candidates, we often lack the ability to make sense of it; hence, we rely on the advice of trusted friends, colleagues, or advisors\n",
    "* “Viral marketing” effects in the success of new products\n",
    "* Adoption of medical and agricultural innovations\n",
    "* Cascading failures in power systems\n",
    "* Desicion making by majority voting\n",
    "\n",
    "Let us consider these models on directed Erdos Renyi graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 20\n",
    "G = nx.erdos_renyi_graph(n, 0.11, 0, True)\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "pos = nx.kamada_kawai_layout(G)\n",
    "nx.draw(G, pos, with_labels=True, node_color='white', edgecolors='black')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1. Linear threshold model (2 point)\n",
    "\n",
    "Linear threshold model is defined as follows. Given a choice of all nodes’ thresholds, and an initial set of active nodes, the diffusion process unfolds deterministically in discrete steps: in step $t$, all nodes that were\n",
    "active in step $t-1$ remain active; furthermore, each currently inactive node becomes active if and only\n",
    "if the total share of its active neighbors is at least node's threshold.\n",
    "\n",
    "Write a function `linear_threshold` that takes a graph, np.array `active_nodes` with zeros and ones (if `active_nodes[i]` is 1 then the i-th node is active), np.array of `thresholds`. The function propagates influence and stops when the model stops changing. The function returns a np.array with active nodes in each step. The first step is initial activation, the last and the second to last steps are the same (we want to see that the model stops changing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "26b04476cb17bab7e6003418f9408a69",
     "grade": false,
     "grade_id": "cell-515144b932e0af91",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def linear_threshold(G, active_nodes, thresholds):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "21ba6c0d4c26105a81744776b9ea55f5",
     "grade": true,
     "grade_id": "cell-a0c0e429d4f73e24",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(5)\n",
    "active_nodes = np.zeros(n, 'int')\n",
    "active_nodes[np.random.choice(np.arange(n), 2, False)] = 1\n",
    "thresholds = np.random.uniform(0.5, 1, n)\n",
    "\n",
    "sim = linear_threshold(G, active_nodes, thresholds)\n",
    "\n",
    "assert sim.shape == (4, 20)\n",
    "assert np.all(sim[0] == active_nodes)\n",
    "assert np.all(sim[-1] == sim[-2])\n",
    "assert sim[0, 4] == 0\n",
    "assert sim[2, 4] == 1\n",
    "assert sim[0, 3] == 0\n",
    "assert sim[1, 15] == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6*2, 4*2))\n",
    "\n",
    "for i, color in enumerate(sim):\n",
    "    plt.subplot(2, 2, i+1)\n",
    "    nx.draw(G, pos, with_labels=True, \n",
    "            node_color=color+1, \n",
    "            vmin=0, vmax=2, \n",
    "            cmap=plt.cm.rainbow,\n",
    "            edgecolors='black')\n",
    "    plt.title('Step {}'.format(i))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2. Independent cascade model (2 points)\n",
    "\n",
    "The next type is Independent cascade model. We again start with an initial set of active nodes, and the process unfolds in discrete steps according to the following randomized rule. When node $v$ first becomes active in step $t$, it is given a single chance to activate each currently inactive neighbor $w$; it succeeds with a probability $p_{v,w}$ — a parameter of the system — independently of the history thus far. (If $w$ has multiple newly activated neighbors, their attempts are sequenced in an arbitrary order.) If $v$ succeeds, then $w$ will become active in step $t+1$; but whether or not $v$ succeeds, it cannot make any further attempts to activate $w$ in subsequent steps.\n",
    "\n",
    "Write a function `independent_cascade` that takes a graph, np.array active_nodes with zeros and ones (if active_nodes[i] is 1 then the i-th node is active), np.array with propagation probabilities `prop_proba` for edges ordered by `G.edges`. The function propagates influence and stops when the model stops changing. The function returns a np.array with active nodes in each step. The first step is initial activation, the last and the second to last steps are the same (we want to see that the model stops changing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "485b84d9d49345fdf82ee2964d68b5d0",
     "grade": false,
     "grade_id": "cell-69f6afdb2634041d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def independent_cascade(G, active_nodes, prop_proba):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "604292efecb6908e66950c67803e2c3c",
     "grade": true,
     "grade_id": "cell-3389d2c8f3368404",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "active_nodes = np.zeros(20, 'int')\n",
    "active_nodes[np.random.choice(np.arange(20), 2, False)] = 1\n",
    "prop_proba = np.random.rand(len(G.edges))\n",
    "\n",
    "sims = []\n",
    "n_steps = []\n",
    "for i in range(1000):\n",
    "    sim = independent_cascade(G, active_nodes, prop_proba)\n",
    "    sims.append(sim)\n",
    "    n_steps.append(len(sim))\n",
    "sigma = 1.9165\n",
    "mean = 5.103\n",
    "assert mean - 2*sigma < np.mean(n_steps) < mean + 2*sigma\n",
    "sim = sims[n_steps.index(6)]\n",
    "assert sim.shape == (6, 20)\n",
    "assert np.all(sim[0] == active_nodes)\n",
    "assert np.all(sim[-1] == sim[-2])\n",
    "for i in range(1, 4):\n",
    "    attempts = sim[i] - sim[i-1]\n",
    "    new_active = sim[i+1] - sim[i]\n",
    "    has_edge = False\n",
    "    for j in np.argwhere(attempts == 1):\n",
    "        for k in np.argwhere(new_active == 1):\n",
    "            if G.has_edge(j[0], k[0]):\n",
    "                has_edge = True\n",
    "    assert has_edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6*2, 4*3))\n",
    "\n",
    "for i, color in enumerate(sim):\n",
    "    plt.subplot(3, 2, i+1)\n",
    "    nx.draw(G, pos, with_labels=True, \n",
    "            node_color=color+1, \n",
    "            vmin=0, vmax=2, \n",
    "            cmap=plt.cm.rainbow,\n",
    "            edgecolors='black')\n",
    "    plt.title('Step {}'.format(i))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3. Greedy influence maximization (2 points)\n",
    "\n",
    "The influence is the expected number of active nodes at the end of the process\n",
    "\n",
    "$$\\sigma(A_0) = \\mathbb E[|A_t|]$$\n",
    "\n",
    "where $A_0$ is an initial active nodes and $A_t$ is an active nodes at the end. Linear threshold model is deterministic and then $E[|A_t|] = |A_t|$.\n",
    "\n",
    "The influence maximization problem asks, for a given number of initial active nodes $k$, to find a set of nodes that gives maximum influence. It is NP-hard problem, but a useful property is that it can be solved in polynomial time by greedy optimization with guaranteed performance slightly better than 63%. Proofs are [here](https://theoryofcomputing.org/articles/v011a004/v011a004.pdf). The algorithm is:\n",
    "\n",
    "1. Let $A_0 = \\emptyset$\n",
    "2. For every node $i$, calculate the influence $\\sigma(A_0 \\cup \\{i\\})$\n",
    "3. Put the node with the largest influence into the initial active set $A_0 = A_0 \\cup \\{i\\}$\n",
    "4. Repeat 2-3 until $|A_0| = k$\n",
    "\n",
    "Write a function `greedy_influence_max` that takes a graph, `thresholds` of linear threshold model, number of active nodes `k` and calculates initial active nodes by greedy algorithm. The function returns a np.array with zeros and ones (if `active_nodes[i]` is 1 then the i-th node is active)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "588a67aa154b9090ddc92e5b42fdf5d1",
     "grade": false,
     "grade_id": "cell-ee934f2bc8c7504a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def greedy_influence_max(G, thresholds, k):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e57ac86858005a71fcd82110bdd5cbc3",
     "grade": true,
     "grade_id": "cell-58dc4b2003bdb792",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "n = 100\n",
    "G = nx.erdos_renyi_graph(n, 0.07, 0, True)\n",
    "\n",
    "np.random.seed(0)\n",
    "active_nodes = np.zeros(n, 'int')\n",
    "active_nodes[np.random.choice(np.arange(n), 2, False)] = 1\n",
    "thresholds = np.random.uniform(0.1, 0.8, n)\n",
    "\n",
    "best_active = greedy_influence_max(G, thresholds, 2)\n",
    "assert best_active.shape == (100,)\n",
    "assert best_active.sum() == 2\n",
    "sim = linear_threshold(G, best_active, thresholds)\n",
    "assert sim[-1].sum() > 21 * 0.63"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the same model as in the linear threshold task, but with a better initial active set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 20\n",
    "G = nx.erdos_renyi_graph(n, 0.11, 0, True)\n",
    "\n",
    "np.random.seed(5)\n",
    "active_nodes = np.zeros(n, 'int')\n",
    "active_nodes[np.random.choice(np.arange(n), 2, False)] = 1\n",
    "thresholds = np.random.uniform(0.5, 1, n)\n",
    "\n",
    "best_active = greedy_influence_max(G, thresholds, 2)\n",
    "sim = linear_threshold(G, best_active, thresholds)\n",
    "\n",
    "plt.figure(figsize=(6*2, 4*4))\n",
    "\n",
    "for i, color in enumerate(sim):\n",
    "    plt.subplot(4, 2, i+1)\n",
    "    nx.draw(G, pos, with_labels=True, \n",
    "            node_color=color+1, \n",
    "            vmin=0, vmax=2, \n",
    "            cmap=plt.cm.rainbow,\n",
    "            edgecolors='black')\n",
    "    plt.title('Step {}'.format(i))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4. Schelling's segregation model (2 points)\n",
    "\n",
    "The second part of the assignment is devoted to agent based models: the Schelling's segregation model and game of life model.\n",
    "\n",
    "We consider Schelling's segregation model on the original structure — 2D regular grid with diagonal edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agent_grid(n):\n",
    "    G = nx.grid_2d_graph(n, n)\n",
    "    for node_i in G.nodes:\n",
    "        for node_j in G.nodes:\n",
    "            if node_i == node_j: continue\n",
    "            if (node_i[0] - 1, node_i[1] + 1) == (node_j[0], node_j[1]):\n",
    "                G.add_edge(node_i, node_j)\n",
    "            if (node_i[0] + 1, node_i[1] + 1) == (node_j[0], node_j[1]):\n",
    "                G.add_edge(node_i, node_j)\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "G = agent_grid(5)\n",
    "pos = {node:node for node in G.nodes}\n",
    "nx.draw(G, pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this model, we have $n$ nodes and $k$ agents, where $k < n$.  Any agent is located in some specific node, so there are $k - n$ empty nodes. All agents are divided into type 0 and type 1. Here is an example of initial positions of agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "n_agents = int(len(G) * 0.9)\n",
    "agent_type = np.random.randint(2, size=n_agents)\n",
    "agent_loc = []\n",
    "for i in np.random.choice(range(len(G)), n_agents, False):\n",
    "    agent_loc.append(list(G.nodes)[i])\n",
    "\n",
    "colors = plt.cm.tab10.colors[1:]\n",
    "node_color = []\n",
    "for node in G.nodes:\n",
    "    if node not in agent_loc:\n",
    "        node_color.append((1, 1, 1))\n",
    "    else:\n",
    "        node_color.append(colors[agent_type[agent_loc.index(node)]])\n",
    "plt.figure(figsize=(5,5))\n",
    "nx.draw(G, pos, node_color=node_color)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model runs as follows:\n",
    "1. For each agent, calculate a share of nearest neighbors with opposite type. For example, if a node has 3 neighbors with opposite type and 4 neighbors with the same type, then the share will be 3/7.\n",
    "2. If the share is bigger than some tolerance level, then the agent is labeled as unhappy.\n",
    "3. Any unhappy agent relocates to a random empty node.\n",
    "4. The process repeats until there are almost no unhappy agents left or max iterations is exceeded.\n",
    "\n",
    "Here is a function `segregation_model` that takes parameters\n",
    "* `G` — a graph\n",
    "* `n_agents` — number of agents\n",
    "* `agent_type` — np.array with zeros and ones. If `agent_type[i]` is 1 then the i-th agent has the type 1.\n",
    "* `agent_loc` — np.array with agent locations. The i-th agent is located in the `agent_loc[i]` node.\n",
    "* `tolerance` — tolerance level\n",
    "* `happiness_threshold` — simulation stops if a happiness threshold is exceeded. Happiness is a share of happy agents.\n",
    "* `max_iter` — maximum number of simulation steps\n",
    "\n",
    "The function runs a simulation and returns agent locations in each step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segregation_model(G, n_agents, agent_type, agent_loc, \n",
    "                      tolerance, happiness_threshold=0.95, \n",
    "                      max_iter=100):\n",
    "    simulation = [agent_loc.copy()]\n",
    "    happiness = []\n",
    "    for _ in range(max_iter):\n",
    "        unhappy_agents = unhappy(G, n_agents, agent_type, \n",
    "                                 agent_loc, tolerance)\n",
    "        happiness.append(1 - len(unhappy_agents) / n_agents)\n",
    "        if unhappy_agents:\n",
    "            empty_loc = list(set(G.nodes).difference(agent_loc))\n",
    "            np.random.shuffle(unhappy_agents)\n",
    "            np.random.shuffle(empty_loc)\n",
    "            for i in range(min(len(unhappy_agents), len(empty_loc))):\n",
    "                agent_loc[unhappy_agents[i]] = empty_loc[i]\n",
    "        simulation.append(agent_loc.copy())\n",
    "        if happiness[-1] > happiness_threshold:\n",
    "            break\n",
    "    happiness.append(happiness[-1])\n",
    "    return simulation, happiness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function `unhappy` that takes parameters of `segregation_model` except of `happiness_threshold` and `max_iter`. The function returns a list of unhappy agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "76dd4e2025364b58cef829bbc0ce1dec",
     "grade": false,
     "grade_id": "cell-e157abb67170cee9",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def unhappy(G, n_agents, agent_type, agent_loc, tolerance):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fa8c77fe55d7fade6e1fb5a07d0ac2ef",
     "grade": true,
     "grade_id": "cell-3d40d6bf078c5d9c",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "n = 40\n",
    "G = agent_grid(n)\n",
    "\n",
    "np.random.seed(0)\n",
    "n_agents = int(len(G) * 0.9)\n",
    "agent_type = np.random.randint(2, size=n_agents)\n",
    "agent_loc = []\n",
    "for i in np.random.choice(range(len(G)), n_agents, False):\n",
    "    agent_loc.append(list(G.nodes)[i])\n",
    "tolerance = 3/7\n",
    "\n",
    "unhappy_agents = unhappy(G, n_agents, agent_type, agent_loc, tolerance)\n",
    "assert len(unhappy_agents) == 831\n",
    "assert sum(unhappy_agents) == 585386\n",
    "assert unhappy_agents[655] == 1138"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us make an animation of the simulation by `matplotlib.animation.FuncAnimation`. Here are auxiliary cells to prepare matplotlib objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update(i):\n",
    "    node_color = []\n",
    "    for node in G.nodes:\n",
    "        if node not in sim[i]:\n",
    "            node_color.append((1, 1, 1))\n",
    "        else:\n",
    "            node_color.append(colors[agent_type[sim[i].index(node)]])\n",
    "    ax.set_title('Happiness: {:.2f}'.format(happiness[i]))\n",
    "    img = np.array(node_color).reshape((n, n, 3))\n",
    "    im.set_data(img)\n",
    "    return(im,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "sim, happiness = segregation_model(G, n_agents, agent_type, \n",
    "                                   agent_loc, tolerance, 0.99, 100)\n",
    "\n",
    "node_color = []\n",
    "for node in G.nodes:\n",
    "    if node not in sim[0]:\n",
    "        node_color.append((1, 1, 1))\n",
    "    else:\n",
    "        node_color.append(colors[agent_type[sim[0].index(node)]])\n",
    "\n",
    "fig = plt.figure(figsize=(6, 6))\n",
    "ax = fig.add_axes([0.1, 0.1, 0.8, 0.8])\n",
    "plt.axis('off')\n",
    "img = np.array(node_color).reshape((n, n, 3))\n",
    "ax.set_title('Happiness: {:.2f}'.format(happiness[0]))\n",
    "im = plt.imshow(img, interpolation='none')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an animation of the segregation model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ani = FuncAnimation(fig, func=update, frames=len(sim))\n",
    "HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5. Game of life model (2 points)\n",
    "\n",
    "Game of life is also an agent model that based on simple rules:\n",
    "1. Any node can be alive or dead.\n",
    "2. If an alive node has 2 or 3 alive neighbors, it stays alive, otherwise it dies\n",
    "3. If a dead node has 3 alive neighbors, it comes to life\n",
    "\n",
    "At each step, we calculate behavior of each node and then simultaneously change behavior of all nodes.\n",
    "\n",
    "Write a function `game_of_life` that takes a graph, np.array `alive` with ones and zeros where `alive[i]` is equal to 1 if a node `i` is alive. Also a number of steps `k` is passed. The function returns a np.array with alive nodes at each step (it is also array with zeros and ones). The number of steps is `k+1` and the first step contains initial alive nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8bd7cc94ecd9a6343be37bbe8d3e8135",
     "grade": false,
     "grade_id": "cell-6c6ed2cfe2dca14e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def game_of_life(G, alive, k=10):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fa2981959d54d6aca31e9f4b9c35a005",
     "grade": true,
     "grade_id": "cell-7c67c710df50fd37",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "n = 30\n",
    "G = agent_grid(n)\n",
    "pos = {node:node for node in G.nodes}\n",
    "G = nx.convert_node_labels_to_integers(G)\n",
    "\n",
    "alive = np.zeros(n * n, 'int')\n",
    "alive[np.random.choice(range(n * n), int(n * n * 0.2), False)] = 1\n",
    "\n",
    "sim = game_of_life(G, alive, 100)\n",
    "assert sim.shape == (101, 900)\n",
    "assert sim[0].sum() == 180\n",
    "assert sim[1].sum() == 176\n",
    "assert sim[2].sum() == 151"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are auxiliary cells to prepare matplotlib objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def animate(i):\n",
    "    im.set_data(sim[i].reshape((n, n)))\n",
    "    return(im,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6, 6))\n",
    "plt.axis('off')\n",
    "im = plt.imshow(sim[0].reshape((n, n)), \n",
    "                cmap=plt.cm.OrRd, interpolation='none')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an animation of the game of life."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ani = FuncAnimation(fig, animate, frames=len(sim))\n",
    "HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
